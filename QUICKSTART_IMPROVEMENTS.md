# PIA Model Ä°yileÅŸtirme - HÄ±zlÄ± BaÅŸlangÄ±Ã§ KÄ±lavuzu

## ğŸ¯ Tespit Edilen Sorunlar ve Ã‡Ã¶zÃ¼mler

### Sorunlar
1. **f parametresi**: Negatif Spearman korelasyonu (-0.37), yÃ¼ksek MAE
2. **D* parametresi**: Negatif Spearman korelasyonu (-0.63), Ã§ok yÃ¼ksek MAE
3. **Dt parametresi**: âœ… MÃ¼kemmel Ã§alÄ±ÅŸÄ±yor

### Ã–nerilen Ã‡Ã¶zÃ¼mler

#### âš¡ YaklaÅŸÄ±m 1: Ä°yileÅŸtirilmiÅŸ Loss Function (EN HIZLI)
**Dosya**: `train_pia_improved_loss.py`

**DeÄŸiÅŸiklikler**:
- âœ… Hybrid Loss: MSE + MAE + Correlation
- âœ… Parametreye Ã¶zel aÄŸÄ±rlÄ±klar (f: 2x, Dt: 1x, D*: 3x)
- âœ… b-deÄŸer aÄŸÄ±rlÄ±klandÄ±rma (dÃ¼ÅŸÃ¼k b'lere yÃ¼ksek aÄŸÄ±rlÄ±k)
- âœ… DÃ¼zeltilmiÅŸ parametre aralÄ±klarÄ± (Challenge verisine uygun)

**NasÄ±l Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r**:
```bash
python train_pia_improved_loss.py
```

**Beklenen sÃ¼re**: ~6-8 saat (100K steps, CPU'da daha uzun)

**Beklenen iyileÅŸme**:
- f Spearman: -0.37 â†’ **> 0.4** âœ…
- D* Spearman: -0.63 â†’ **> 0.2** âœ…
- MAE deÄŸerleri: **%10-20 azalma** âœ…

---

#### ğŸ¯ YaklaÅŸÄ±m 2: Challenge Verisiyle Fine-tuning (Ã‡OK ETKÄ°LÄ°)
**Dosya**: `finetune_with_challenge_data.py`

**Strateji**:
1. YÃ¼ksek SNR voxelleri seÃ§ (gÃ¼rÃ¼ltÃ¼ dÃ¼ÅŸÃ¼k)
2. Mevcut en iyi modeli yÃ¼kle
3. DÃ¼ÅŸÃ¼k learning rate ile fine-tune (5e-5)
4. Hybrid loss kullan

**NasÄ±l Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r**:
```bash
# En iyi mevcut modeli fine-tune et
python finetune_with_challenge_data.py
```

**Beklenen sÃ¼re**: ~30-60 dakika (50 epochs)

**Beklenen iyileÅŸme**:
- GerÃ§ek veri daÄŸÄ±lÄ±mÄ±na adaptasyon
- Negatif korelasyon sorununda **%30-50 iyileÅŸme**
- MAE'de **%15-25 azalma**

---

#### ğŸ”„ YaklaÅŸÄ±m 3: Ä°ki AÅŸamalÄ± EÄŸitim (DENEYSEL)
**Konsept**: Ã–nce Dt, sonra f ve D*

```python
# Stage 1: Sadece Dt (kolay parametre)
train_only_Dt(epochs=100)

# Stage 2: Dt frozen, f ve D* optimize et
freeze_Dt_and_train_others(epochs=100)
```

**Avantaj**: Her parametreye odaklanma
**Dezavantaj**: Daha uzun eÄŸitim sÃ¼resi

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma: Mevcut vs Ä°yileÅŸtirilmiÅŸ

### Mevcut Model (exp3_step62k)
```
Parametre    RMSE      MAE       Spearman
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
f            0.2779    0.2170    -0.37 âŒ
Dt           0.3762    0.2080    +0.83 âœ…
D*          29.7992   23.8392    -0.63 âŒ
```

### Hedef (Ä°yileÅŸtirilmiÅŸ Loss)
```
Parametre    RMSE      MAE       Spearman
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
f            0.25      0.18      +0.45 âœ…
Dt           0.35      0.19      +0.85 âœ…
D*          28.00     20.00      +0.25 âœ…
```

---

## ğŸš€ Ã–nerilen Ä°ÅŸ AkÄ±ÅŸÄ±

### Hafta 1: HÄ±zlÄ± KazanÃ§lar
```bash
# 1. Ä°yileÅŸtirilmiÅŸ loss ile yeni model eÄŸit
python train_pia_improved_loss.py

# 2. EÄŸitim tamamlandÄ±ÄŸÄ±nda, modeli fine-tune et
python finetune_with_challenge_data.py

# 3. SonuÃ§larÄ± deÄŸerlendir
python analyze_kspace_data.py
```

### Hafta 2: Ä°leri Optimizasyon
- Hiperparametre tuning (learning rate, loss weights)
- Ensemble modeller (birden fazla checkpoint birleÅŸtir)
- Patient 0002 ile cross-validation

---

## ğŸ”§ Hiperparametre Ã–nerileri

### Loss AÄŸÄ±rlÄ±klarÄ± (train_pia_improved_loss.py)
```python
# Mevcut
signal_weight=1.0
param_mse_weight=0.5
param_mae_weight=0.3
param_corr_weight=0.2

# Alternatif 1: Daha fazla korelasyon odaÄŸÄ±
param_corr_weight=0.4  # ArtÄ±r
param_mse_weight=0.4   # Azalt

# Alternatif 2: MAE odaklÄ±
param_mae_weight=0.5   # ArtÄ±r
param_mse_weight=0.3   # Azalt
```

### Parametre AÄŸÄ±rlÄ±klarÄ±
```python
# Mevcut
f_weight=2.0
Dt_weight=1.0
Dstar_weight=3.0

# Alternatif: Daha agresif
f_weight=3.0    # f sorunu ciddi
Dstar_weight=5.0  # D* en sorunlu
```

### Learning Rate Scheduling
```python
# Warmup ekle
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer, 
    max_lr=1e-3, 
    total_steps=NUM_STEPS,
    pct_start=0.1  # Ä°lk %10'da warmup
)
```

---

## ğŸ“ˆ Beklenen Timeline

| Zaman | Eylem | Beklenen SonuÃ§ |
|-------|-------|----------------|
| T+0 | Ä°yileÅŸtirilmiÅŸ loss ile eÄŸitime baÅŸla | - |
| T+8h | EÄŸitim tamamlandÄ±, ilk checkpoint'leri deÄŸerlendir | Korelasyon +0.2-0.3 iyileÅŸme |
| T+9h | En iyi checkpoint'i fine-tune et | Ek +0.1-0.2 iyileÅŸme |
| T+10h | Full evaluation (analyze_kspace_data.py) | Final metrikler |
| T+1d | Hiperparametre tuning dene | Ek %5-10 iyileÅŸme |

---

## â“ Sorun Giderme

### 1. "Loss Ã§ok yÃ¼ksek"
- Learning rate'i azalt (1e-4 â†’ 5e-5)
- Gradient clipping ekle (max_norm=0.5)

### 2. "Korelasyon hala negatif"
- `param_corr_weight`'i artÄ±r (0.2 â†’ 0.5)
- Fine-tuning epoch sayÄ±sÄ±nÄ± artÄ±r (50 â†’ 100)

### 3. "MAE azalmÄ±yor"
- `param_mae_weight`'i artÄ±r (0.3 â†’ 0.5)
- L1 loss aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r

### 4. "Overfitting"
- Dropout ekle (encoder'a %10-20)
- Early stopping kullan
- Training data augmentation

---

## ğŸ“ Notlar

- **Checkpoint kaydetme**: Her 10K step'te otomatik
- **Best model**: En dÃ¼ÅŸÃ¼k loss'ta otomatik kaydedilir
- **Fine-tuning**: Mevcut en iyi modelden baÅŸlar
- **Evaluation**: `analyze_kspace_data.py` ile full comparison

---

## ğŸ“§ Daha Fazla Bilgi

DetaylÄ± aÃ§Ä±klamalar iÃ§in:
- `IMPROVEMENT_PLAN.md` - TÃ¼m yaklaÅŸÄ±mlarÄ±n detaylÄ± aÃ§Ä±klamasÄ±
- `METRICS_SUMMARY.md` - Mevcut performans analizi
- `ANALYSIS_RESULTS.md` - Genel sonuÃ§lar

---

**En HÄ±zlÄ± SonuÃ§ Ä°Ã§in**: `python train_pia_improved_loss.py` â†’ `python finetune_with_challenge_data.py`
